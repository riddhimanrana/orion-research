# Data Directory Structure

## 📁 Overview

This directory contains datasets, benchmarks, and cached data for Orion's CIS training.

```
data/
├── aspire_train.json          # TAO-Amodal training annotations (201MB, Git LFS)
├── aspire_test.json           # TAO-Amodal test annotations (259MB, Git LFS)
├── benchmarks/
│   └── ground_truth/
│       ├── vsgr_aspire_train_full.json    # VSGR causal labels (all videos)
│       └── vsgr_aspire_train_sample.json  # VSGR causal labels (sample)
├── examples/
│   └── video.mp4              # Example video for testing Orion
└── hpo/
    ├── extracted_test.pkl     # Cached processed tracks (for speed)
    └── annotation_template.json
```

---

## 📊 File Purposes

### **TAO-Amodal Annotations** (aspire_*.json)
- **Source**: VSGR dataset (based on TAO-Amodal benchmark)
- **Content**: Bounding box tracks for objects in videos
  - Video metadata (width, height, fps)
  - Track IDs with frame-by-frame bounding boxes
  - Object categories
- **Used by**: `orion/hpo/tao_data_loader.py`
- **Format**: See TAO-Amodal documentation
- **Note**: Stored in Git LFS due to size (>100MB)

### **VSGR Ground Truth** (benchmarks/ground_truth/)
- **Source**: VSGR paper's causality annotations
- **Content**: Labeled causal relationships
  ```json
  {
    "video_id": "ArgoVerse/...",
    "cause_track_id": 123,
    "effect_track_id": 456,
    "frame_range": [10, 50]
  }
  ```
- **Used by**: CIS training to validate predictions
- **Purpose**: Training labels for hyperparameter optimization

### **Processed Cache** (hpo/)
- **Purpose**: Speed up training by caching extracted tracks
- **Generated by**: `TAODataLoader` on first run
- **Safe to delete**: Will be regenerated if missing

---

## 🔄 Workflow

1. **Download TAO-Amodal** (if not present):
   ```bash
   # These are already included via Git LFS
   git lfs pull
   ```

2. **Training loads**:
   - Reads `aspire_train.json` → extracts tracks
   - Reads `vsgr_aspire_train_full.json` → gets labels
   - Caches to `hpo/extracted_test.pkl`

3. **Orion analyze** uses trained weights:
   - Reads `hpo_results/cis_weights.json`
   - Applies to video analysis

---

## 📥 Getting Data on New Computer

```bash
# Clone with LFS support
git lfs install
git clone <repo-url>
cd orion-research

# Pull large files
git lfs pull

# Verify files exist
ls -lh data/aspire_*.json
```

---

## 🔧 Troubleshooting

### "File not found" errors
```bash
# Pull LFS files
git lfs pull
```

### Out of space
```bash
# Use only sample data (much smaller)
python scripts/train_cis.py --max-videos 5
```

### Corrupted cache
```bash
# Delete and regenerate
rm data/hpo/extracted_test.pkl
python scripts/train_cis.py  # Will regenerate
```

---

## 📝 Notes

- **aspire_train.json** contains 2,647 tracks from 38 videos
- **VSGR labels** provide ground truth for 38 causal pairs
- Training extracts ~145 agent candidates per video
- Cache saves ~5-10 seconds per training run
